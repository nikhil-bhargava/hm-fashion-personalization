{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "893c7b52",
      "metadata": {
        "id": "893c7b52"
      },
      "source": [
        "# Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003d19de",
      "metadata": {
        "id": "003d19de"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73de6d30",
      "metadata": {
        "id": "73de6d30"
      },
      "source": [
        "## Data Info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print('yes')\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print('no')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ0GfL8wIwmN",
        "outputId": "404a00f1-64dc-4938-bfa0-2b2fc3fd073a"
      },
      "id": "cZ0GfL8wIwmN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y-n-3H8zCwpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80217226-45c9-44ee-cef4-5a8c460a7344"
      },
      "id": "y-n-3H8zCwpJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e3b0ed",
      "metadata": {
        "id": "27e3b0ed"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/transactions_train.csv', nrows=1000000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles = pd.read_csv('drive/MyDrive/Colab Notebooks/articles.csv')"
      ],
      "metadata": {
        "id": "WoJJKxh0U77P"
      },
      "id": "WoJJKxh0U77P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articles = articles[['article_id', 'prod_name', 'colour_group_name']]"
      ],
      "metadata": {
        "id": "LbE1uUTOU-ca"
      },
      "id": "LbE1uUTOU-ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(articles, how='left', on='article_id')"
      ],
      "metadata": {
        "id": "54rArvnMVXl7"
      },
      "id": "54rArvnMVXl7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create unbought data\n",
        "df2 = pd.DataFrame()\n",
        "df2['customer_id'] = df['customer_id'].sample(n=len(df))\n",
        "df2['prod_name'] = df['prod_name'].sample(n=len(df))\n",
        "df2['total_bought'] = 0"
      ],
      "metadata": {
        "id": "bx7oGJXwc9Wv"
      },
      "id": "bx7oGJXwc9Wv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95ccee80",
      "metadata": {
        "id": "95ccee80"
      },
      "outputs": [],
      "source": [
        "data = df.groupby(['customer_id', 'prod_name'])['customer_id'].count().reset_index(name='total_bought')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data, df2]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "SEiSAUmvedvq"
      },
      "id": "SEiSAUmvedvq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['total_bought'] = np.where(data['total_bought'] > 2, 2, data['total_bought'])"
      ],
      "metadata": {
        "id": "f4-t1iwm2FMR"
      },
      "id": "f4-t1iwm2FMR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_join = df.drop_duplicates(subset=['customer_id', 'prod_name'])\n",
        "data = data.merge(color_join, how='left', on=['customer_id', 'prod_name'])"
      ],
      "metadata": {
        "id": "8D6GKSEbZjtU"
      },
      "id": "8D6GKSEbZjtU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2c2941",
      "metadata": {
        "id": "6e2c2941"
      },
      "outputs": [],
      "source": [
        "# Encode the genres data\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(data['customer_id'])\n",
        "data['encoded_customer_id'] = encoder.transform(data['customer_id'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the genres data\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(data['prod_name'])\n",
        "data['encoded_prod_name'] = encoder.transform(data['prod_name'])"
      ],
      "metadata": {
        "id": "ogtyqukNVMyL"
      },
      "id": "ogtyqukNVMyL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the genres data\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(data['colour_group_name'])\n",
        "data['encoded_colour_group_name'] = encoder.transform(data['colour_group_name'])"
      ],
      "metadata": {
        "id": "Gjrc1ofwZc4F"
      },
      "id": "Gjrc1ofwZc4F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f23b1c9",
      "metadata": {
        "id": "4f23b1c9"
      },
      "outputs": [],
      "source": [
        "X = data.loc[:,['encoded_customer_id','encoded_prod_name','encoded_colour_group_name']]\n",
        "y = data.loc[:,'total_bought']\n",
        "\n",
        "# Split our data into training and test sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=0, test_size=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d91b83",
      "metadata": {
        "id": "d8d91b83"
      },
      "outputs": [],
      "source": [
        "def prep_dataloaders(X_train,y_train,X_val,y_val,batch_size):\n",
        "    # Convert training and test data to TensorDatasets\n",
        "    trainset = TensorDataset(torch.from_numpy(np.array(X_train)).long(), \n",
        "                            torch.from_numpy(np.array(y_train)).float())\n",
        "    valset = TensorDataset(torch.from_numpy(np.array(X_val)).long(), \n",
        "                            torch.from_numpy(np.array(y_val)).float())\n",
        "\n",
        "    # Create Dataloaders for our training and test data to allow us to iterate over minibatches \n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return trainloader, valloader\n",
        "\n",
        "batchsize = 64\n",
        "trainloader,valloader = prep_dataloaders(X_train,y_train,X_val,y_val,batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c130d1",
      "metadata": {
        "id": "d9c130d1"
      },
      "outputs": [],
      "source": [
        "class NNHybridFiltering(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_users, n_items, n_genres, embdim_users, embdim_items, embdim_genres, n_activations, rating_range):\n",
        "        super().__init__()\n",
        "        self.user_embeddings = nn.Embedding(num_embeddings=n_users,embedding_dim=embdim_users)\n",
        "        self.item_embeddings = nn.Embedding(num_embeddings=n_items,embedding_dim=embdim_items)\n",
        "        self.genre_embeddings = nn.Embedding(num_embeddings=n_genres,embedding_dim=embdim_genres)\n",
        "        self.fc1 = nn.Linear(embdim_users+embdim_items+embdim_genres,n_activations)\n",
        "        self.fc2 = nn.Linear(n_activations,1)\n",
        "        self.rating_range = rating_range\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Get embeddings for minibatch\n",
        "        embedded_users = self.user_embeddings(X[:,0])\n",
        "        embedded_items = self.item_embeddings(X[:,1])\n",
        "        embedded_genres = self.genre_embeddings(X[:,2])\n",
        "        # Concatenate user, item and genre embeddings\n",
        "        embeddings = torch.cat([embedded_users,embedded_items,embedded_genres],dim=1)\n",
        "        # Pass embeddings through network\n",
        "        preds = self.fc1(embeddings)\n",
        "        preds = F.relu(preds)\n",
        "        preds = self.fc2(preds)\n",
        "        # Scale predicted ratings to target-range [low,high]\n",
        "        preds = torch.sigmoid(preds) * (self.rating_range[1]-self.rating_range[0]) + self.rating_range[0]\n",
        "        return preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f717259e",
      "metadata": {
        "id": "f717259e"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, dataloaders, device, num_epochs=5, scheduler=None):\n",
        "    model = model.to(device) # Send model to GPU if available\n",
        "    since = time.time()\n",
        "\n",
        "    costpaths = {'train':[],'val':[]}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            # Get the inputs and labels, and send to GPU if available\n",
        "            for (inputs,labels) in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the weight gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass to get outputs and calculate loss\n",
        "                # Track gradient only for training data\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model.forward(inputs).view(-1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backpropagation to get the gradients with respect to each weight\n",
        "                    # Only if in train\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        # Update the weights\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Convert loss into a scalar and add it to running_loss\n",
        "                running_loss += np.sqrt(loss.item()) * labels.size(0)\n",
        "\n",
        "            # Step along learning rate scheduler when in train\n",
        "            if (phase == 'train') and (scheduler is not None):\n",
        "                scheduler.step()\n",
        "\n",
        "            # Calculate and display average loss and accuracy for the epoch\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            costpaths[phase].append(epoch_loss)\n",
        "            print('{} loss: {:.4f}'.format(phase, epoch_loss))\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    return costpaths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "023c967f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "023c967f",
        "outputId": "caeff768-d69d-41b5-cc15-f13236c8dea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train loss: 0.6253\n",
            "val loss: 0.6259\n",
            "Epoch 1/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Epoch 2/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Epoch 3/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Epoch 4/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Epoch 5/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6260\n",
            "Epoch 6/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Epoch 7/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Epoch 8/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Epoch 9/9\n",
            "----------\n",
            "train loss: 0.6249\n",
            "val loss: 0.6259\n",
            "Training complete in 30m 3s\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "dataloaders = {'train':trainloader, 'val':valloader}\n",
        "n_users = X.loc[:,'encoded_customer_id'].max()+1\n",
        "n_items = X.loc[:,'encoded_prod_name'].max()+1\n",
        "n_genres = X.loc[:,'encoded_colour_group_name'].max()+1\n",
        "model = NNHybridFiltering(n_users,\n",
        "                       n_items,\n",
        "                       n_genres,\n",
        "                       embdim_users=50, \n",
        "                       embdim_items=50, \n",
        "                       embdim_genres=25,\n",
        "                       n_activations = 100,\n",
        "                       rating_range=[0., 2.])\n",
        "criterion = nn.MSELoss()\n",
        "lr=0.001\n",
        "n_epochs=10\n",
        "wd=1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "cost_paths = train_model(model,criterion,optimizer,dataloaders, device,n_epochs, scheduler=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating(model, userId, movieId, genre, encoder, device):\n",
        "    # Encode genre\n",
        "    genre = encoder.transform(np.array(genre).reshape(-1))\n",
        "    # Get predicted rating\n",
        "    model = model.to(device)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        X = torch.Tensor([userId,movieId,genre]).long().view(1,-1)\n",
        "        X = X.to(device)\n",
        "        pred = model.forward(X)\n",
        "        return pred\n",
        "\n",
        "# Get the predicted rating for a random user-item pair\n",
        "rating = predict_rating(model,userId=133785,movieId=2156,genre='Green',encoder=encoder, device=device)\n",
        "print('Predicted rating is {:.1f}'.format(rating.detach().cpu().item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49YDfCso0JDb",
        "outputId": "e1c1d29e-9d8b-4ba3-ad58-9dcbc6922b94"
      },
      "id": "49YDfCso0JDb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating is 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_customers = list(X_val.encoded_customer_id.unique())[:100]\n",
        "test_prod = list(data.encoded_prod_name.unique())[:1000]\n",
        "colors = list(data.colour_group_name.unique())\n",
        "\n",
        "recommendations = {}\n",
        "for customer in test_customers:\n",
        "  customer_recs = {}\n",
        "  prod_color = {}\n",
        "  for prod in test_prod:\n",
        "    init_rating = 0\n",
        "    prod_col = None\n",
        "    # for color in colors:\n",
        "    rating = predict_rating(model,userId=customer,movieId=prod,genre='Black',encoder=encoder, device=device)\n",
        "      # print(prod, color, rating)\n",
        "      # if rating >= init_rating:\n",
        "      #   init_rating = rating\n",
        "      #   top_color = color\n",
        "    customer_recs[prod] = init_rating\n",
        "    # prod_color[prod] = top_color\n",
        "  sorted_customer_recs = {k: v for k, v in sorted(customer_recs.items(), key=lambda item: item[1])}\n",
        "  recs = list(sorted_customer_recs.keys())[:12]\n",
        "  recommendations[customer] = recs"
      ],
      "metadata": {
        "id": "gwWMhAi2fgeB"
      },
      "id": "gwWMhAi2fgeB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mAP_list = []\n",
        "for customer in recommendations:\n",
        "    top_recs = recommendations[customer]\n",
        "    actual_bought = list(data[data['encoded_customer_id'] == customer].groupby(['encoded_prod_name'])['customer_id'].count().sort_values(ascending=False).index.values.astype('int'))\n",
        "    correct = len(set(actual_bought).intersection(set(top_recs)))\n",
        "    ap = correct / len(actual_bought)\n",
        "    mAP_list.append(ap)\n",
        "np.array(mAP_list).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxPY5BHIDZOe",
        "outputId": "90d1b8ac-e0d0-47fa-ee65-a64c5d11638f"
      },
      "id": "pxPY5BHIDZOe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009964285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "nn-hydrid-recsystems.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "ed72516f",
        "76c4dc91"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}